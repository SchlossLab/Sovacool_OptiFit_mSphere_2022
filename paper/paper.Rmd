---
title: "OptiFit: an improved method for fitting amplicon sequences to existing OTUs"
date: '`r Sys.Date()`'
bibliography: references.bib
link-citations: true
output:
  pdf_document:
    includes:
      in_header: preamble.tex
      before_body: head.tex
    fig_caption: yes
  github_document:
    includes:
      in_header: preamble.tex
      before_body: head.tex
    html_preview: false
csl: msystems.csl
fontsize: 12pt
geometry: margin=1.0in
repository_url: https://github.com/SchlossLab/OptiFitAnalysis
params:
    snakemake: "none"
---

```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
schtools::set_knitr_opts()
knitr::opts_chunk$set(fig.path = here::here('figures/'),
                      dpi = 300)
```

```{r deps, include=FALSE, message = FALSE}
library(assertthat)
library(cowplot)
library(glue)
library(here)
library(knitr)
library(schtools)
library(tidyverse)
set.seed(20210624)
snakemake <- params$snakemake
if (is_character(snakemake)) {
  stop("You need to knit this R Markdown document from the Snakemake workflow")
}
load(here("results", "stats.RData"))

figures_meta <- yaml::read_yaml(here('config', 'figures.yaml'))
figs <- function(fig_name, attribute) {
  value <- figures_meta[[fig_name]][[attribute]]
  if (attribute == 'cap') {
    value <- glue("\\label{fig:[fig_name]}[value]", .open='[', .close = ']')
  } else {
    value <- eval(parse(text = value))
  }
  return(value)
}

close_enough <- function(x, y, tol = 10^-2) {
  assert_that(all(near(x, y, tol = tol)))
}
```

## Abstract

Assigning amplicon sequences to operational taxonomic units (OTUs) is often an
important step in characterizing the composition of microbial communities across
large datasets.
OptiClust, a _de novo_ OTU clustering method, has been
shown to produce higher quality OTU assignments than other methods and at
comparable or faster speeds.
A notable difference between _de novo_ clustering and database-dependent
reference clustering methods is that OTU assignments from _de novo_ methods may
change when new sequences are added to a dataset.
However, in some cases one may wish to incorporate new samples into a previously
clustered dataset without performing clustering again on all sequences, such as
when comparing across datasets or deploying machine learning models where OTUs
are features.
Existing reference-based clustering methods produce consistent OTUs, but they
only consider the similarity of each query sequence to a single reference
sequence in an OTU, thus resulting in OTU assignments that are significantly 
worse than those generated by _de novo_ methods.
To provide an efficient and robust method to fit amplicon sequence data to
existing OTUs, we developed the OptiFit algorithm.
Inspired by OptiClust, OptiFit considers the similarity of all pairs of reference and
query sequences in an OTU to produce OTUs of the best possible quality.
We tested OptiFit using four microbiome datasets with two different strategies:
by clustering to an external reference database or by splitting the dataset into a 
reference and query set and clustering the query sequences to the reference set
after clustering it using OptiClust.
The result is an improved implementation of closed and open-reference clustering.
OptiFit produces OTUs of similar quality as OptiClust and at faster speeds when
using the split dataset strategy, although the OTU quality and processing speed
depends on the database chosen when using the external database strategy.
OptiFit provides a suitable option for users who require consistent OTU
assignments at the same quality afforded by _de novo_ clustering methods.

### Importance

Advancements in DNA sequencing technology have allowed researchers to affordably
generate millions of sequence reads from microorganisms in diverse environments.
Efficient and robust software tools are needed to assign microbial sequences
into taxonomic groups for characterization and comparison of communities.
The OptiClust algorithm produces high quality groups by comparing sequences to
each other, but the assignments can change when new sequences are
added to a dataset, making it difficult to compare different studies.
Other approaches assign sequences to groups by comparing them to
sequences in a reference database to produce consistent assignments, but the
quality of the groups produced is reduced compared to OptiClust.
We developed OptiFit, a new reference-based algorithm that produces consistent
yet high quality assignments like OptiClust.
OptiFit allows researchers to compare microbial communities across different
studies or add new data to existing studies without sacrificing the quality of
the group assignments.

\newpage

## Introduction

Amplicon sequencing is a mainstay of microbial ecology.
Researchers can affordably generate millions of sequences to characterize the
composition of hundreds of samples from microbial communities without the need
for culturing.
In many analysis pipelines, 16S rRNA gene sequences are assigned to
operational taxonomic units (OTUs) to facilitate comparison of taxonomic
composition between communities to avoid the need for taxonomic classification.
A distance threshold of 3% (or sequence similarity of 97%) is commonly used to
cluster sequences into OTUs based on pairwise comparisons of the sequences
within the dataset.
The method chosen for clustering affects the quality of OTU assignments and thus
may impact downstream analyses of community composition
[@westcott_opticlust_2017; @schloss_application_2016;
@westcott_novo_2015].

There are two main categories of OTU clustering algorithms: _de novo_ and
reference-based.
OptiClust is a _de novo_ clustering algorithm which uses the distance score
between all pairs of sequences in the dataset to cluster them into OTUs by
maximizing the Matthews Correlation Coefficient (MCC)
[@westcott_opticlust_2017].
This approach takes into account the distances between all pairs of sequences
when assigning query sequences to OTUs, in contrast to other _de novo_
methods such as the greedy clustering algorithms implemented in USEARCH and
VSEARCH, which only consider the distance between the query sequence and a
representative centroid sequence in the OTU [@edgar_search_2010;
@rognes_vsearch_2016].
In methods employing greedy clustering algorithms, only the distance between
each sequence and the centroid sequence is considered while clustering.
As a result, distances between pairs of sequences in the same OTU are frequenty
larger than the specified threshold, i.e. they are false positives.
In contrast, the OptiClust algorithm takes into account the distance between all
pairs of sequences when considering how to cluster sequences into OTUs and is
thus less willing to take on false positives.
A limitation of _de novo_ clustering is that different OTU assignments will be
produced when new sequences are added to a dataset, making it difficult to use
_de novo_ clustering to compare OTUs between different studies.
Furthermore, since _de novo_ clustering requires calculating and comparing
distances between all sequences in a dataset, the execution time can be slow and
memory requirements can be prohibitive for very large datasets.
Reference clustering attempts to overcome the limitations of _de novo_
clustering methods by using a representative set of sequences from a database,
with each reference sequence seeding an OTU.
Commonly, the Greengenes set of representative full length sequences clustered
at 97% similarity is used as the reference with VSEARCH
[@desantis_greengenes_2006; @rognes_vsearch_2016; @noauthor_clustering_nodate].
Query sequences are then clustered into OTUs based on their similarity to the
reference sequences.
Any query sequences that are not within the distance threshold to any of the
reference sequences are either thrown out (closed reference clustering) or
clustered _de novo_ to create additional OTUs (open reference clustering).
While reference-based clustering is generally fast, it is limited by the
diversity of the reference database.
Novel sequences in the sample will be lost in closed reference mode if
they are not represented by a similar sequence in the database.
Previous studies found that the OptiClust _de novo_ clustering algorithm created
the highest quality OTU assignments of all clustering methods [@westcott_opticlust_2017].

To overcome the limitations of current reference-based and _de novo_ clustering
algorithms while maintaining OTU quality, we developed OptiFit, a
reference-based clustering algorithm.
While other tools represent reference OTUs with a single sequence, OptiFit uses
multiple sequences in existing OTUs as the reference and fits new sequences
those reference OTUs.
In contrast to other tools, OptiFit considers all pairwise distance scores
between reference and query sequences when assigning sequences to OTUs in order
to produce OTUs of the highest possible quality.
Here, we tested the OptiFit algorithm with the reference as a public database
(e.g. Greengenes) or _de novo_ OTUs generated using a reference set from the
full dataset and compared the performance to existing tools.
To evaluate the OptiFit algorithm and compare to existing methods, we used four
published datasets isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples. 
OptiFit is available within the mothur software program.

## Results

### The OptiFit algorithm

OptiFit leverages the method employed by OptiClust of iteratively assigning
sequences to OTUs to produce the highest quality OTUs possible, and extends this
method for reference-based clustering.
OptiClust first seeds each sequence into its own OTU as a singleton. 
Then for each sequence, OptiClust considers whether the sequence should move to
a different OTU or remain in its current OTU, choosing the option that results
in a better Matthews correlation coefficient (MCC) [@westcott_opticlust_2017].
The MCC uses all values from a confusion matrix and ranges from zero to one,
with a score of one occurring when all sequence pairs are true positives and
true negatives, and a score of zero when all pairs are false positives and false
negatives.
Sequence pairs that are similar to each other (i.e. within the distance
threshold) are counted as true positives if they are clustered into the same OTU,
and false negatives if they are not in the the same OTU.
Sequence pairs that are not similar to each other are true negatives if they are
not clustered into the same OTU, and false positives if they are not in the same
OTU.
OptiClust iterations continue until the MCC stabilizes or until a maximum number
of iterations is reached.
This process produces _de novo_ OTU assignments with the most optimal MCC given
the input sequences.

```{r algorithm, fig.dim=figs('algorithm','dim'), fig.cap=figs('algorithm','cap')}
figs('algorithm', 'path') %>% 
  tiff::readTIFF() %>% 
  grid::grid.raster() 
```

OptiFit begins where OptiClust ends, starting with a list of reference OTUs and
their sequences, a list of query sequences to cluster to the reference OTUs, and
the sequence pairs that are within the distance threshold (e.g. 0.03) 
(Figure \ref{fig:algorithm}).
Initially, all query sequences are placed into separate OTUs. 
Then, the algorithm iteratively reassigns the query sequences to the reference 
OTUs to optimize the MCC. 
Alternatively, a sequence will remain unassigned if the MCC value is maximized
when the sequence is a singleton rather than clustered into a reference OTU.
All query and reference sequence pairs are considered when calculating the MCC.
This process is repeated until the MCC changes by no more than 0.0001 (default)
or until a maximum number of iterations is reached (default: 100).
In the closed reference mode, any query sequences that cannot be clustered into
reference OTUs are discarded, and the results only contain OTUs that exist
in the original reference.
In the open reference mode, unassigned query sequences are clustered _de novo_
using OptiClust to generate new OTUs.
The final MCC is reported with the best OTU assignments.
There are two strategies for generating OTUs with OptiFit: 
1) cluster the query sequences to reference OTUs generated by _de novo_ clustering an
independent database, or
2) split the dataset into a reference and query fraction, cluster the reference
sequences _de novo_, then cluster the query sequences to the reference OTUs.

### Reference clustering with public databases

```{r db_names, include = FALSE}
db_names <- names(dn_dbs_mcc)
db_names_upper <- case_when(db_names == 'gg' ~ 'Greengenes', 
                           TRUE ~ toupper(db_names))
close_enough(dn_dbs_mcc['gg'], dn_dbs_mcc['silva'])
close_enough(dn_dbs_mcc['gg'], dn_dbs_mcc['rdp'], 10^-1)
mcc_decreasing <- c(closed_fit_rdp_mcc, closed_fit_silva_mcc, closed_fit_gg_mcc,
                    open_fit_silva_mcc, open_fit_gg_mcc, open_fit_rdp_mcc, 
                    opticlust_mcc)
assert_that(!is.unsorted(mcc_decreasing))
```

To test how OptiFit performs for reference-based clustering, we clustered each
dataset to three databases of reference OTUs: the Greengenes database, the SILVA
non-redundant database, and the Ribosomal Database Project (RDP)
[@desantis_greengenes_2006; @quast_silva_2013; @cole_ribosomal_2014].
Reference OTUs for each database were created by performing _de novo_ clustering
with OptiClust at a distance threshold of 3% using the V4 region of each
sequence (see Figure \ref{fig:workflow}).
The _de novo_ MCC scores were `r dn_dbs_mcc` for `r db_names_upper`,
respectively.
Clustering sequences to Greengenes and SILVA in closed reference mode performed
similarly, with median MCC scores of `r closed_fit_gg_mcc` and 
`r closed_fit_silva_mcc` respectively, while the median MCC 
was `r closed_fit_rdp_mcc` when clustering to RDP 
(Figure \ref{fig:results_sum}).
For comparison, clustering datasets with OptiClust produced an average MCC score
of `r opticlust_mcc`.
This gap in OTU quality mostly disappeared when clustering in open reference
mode, which produced median MCCs of `r open_fit_gg_mcc` with Greengenes, 
`r open_fit_silva_mcc` with SILVA, and `r open_fit_rdp_mcc` with the RDP.
Thus, open reference OptiFit produced OTUs of very similar quality as _de novo_
clustering, and closed reference OptiFit followed closely behind as long as a
suitable reference database was chosen.

```{r workflow, fig.dim=figs('workflow','dim'), fig.cap=figs('workflow','cap')}
figs('workflow', 'path') %>% 
  tiff::readTIFF() %>% 
  grid::grid.raster() 
```

```{r, include = FALSE}
assert_that(!is.unsorted(c(frac_fit_rdp, frac_fit_silva, frac_fit_gg)))
assert_that((frac_fit_gg - frac_fit_silva) < 10)
assert_that((frac_fit_gg - frac_fit_rdp) > 40)
```

Since closed reference clustering does not cluster query sequences that could
not be clustered into reference OTUs, an additional measure of clustering
performance to consider is the fraction of query sequences that were able to be
clustered.
On average, more sequences were clustered with Greengenes as the reference 
(`r frac_fit_gg`%) than with SILVA (`r frac_fit_silva`%) or with the RDP 
(`r frac_fit_rdp`%) (Figure \ref{fig:results_sum}).
This mirrored the result reported above that Greengenes produced better OTUs in
terms of MCC score than either SILVA or RDP.
Note that _de novo_ and open reference clustering methods always cluster 100% of
sequences into OTUs.
The database chosen affects the final closed reference OTU assignments
considerably in terms of both MCC score and fraction of query sequences that
could be clustered into the reference OTUs.

```{r, include = FALSE}
assert_that(!is.unsorted(c(closed_fit_silva_human_sec, 
                           opticlust_human_sec,
                           open_fit_silva_human_sec)))
```


Despite the drawbacks, closed reference methods have been used when fast
execution speed is required, such as when using very large datasets
[@navas-molina_chapter_2013].
To compare performance in terms of speed, we repeated each OptiFit and OptiClust
run 100 times and measured the execution time.
Across all dataset and database combinations, closed reference OptiFit
outperformed both OptiClust and open reference OptiFit (Figure \ref{fig:results_sum}).
For example, with the human dataset fit to SILVA reference OTUs, the average run
times in seconds were `r closed_fit_silva_human_sec` for closed reference
OptiFit, `r opticlust_human_sec` for _de novo_ clustering the dataset, and 
`r open_fit_silva_human_sec` for open reference OptiFit. 
Thus, the OptiFit algorithm continues the precedent that closed reference
clustering sacrifices OTU quality for execution speed.

```{r results_sum, fig.dim=figs('results_sum', 'dim'), fig.cap=figs('results_sum', 'cap')}
figs('results_sum', 'path') %>% 
  tiff::readTIFF() %>% 
  grid::grid.raster() 
```

```{r, include = FALSE}
assert_that(mcc_closed_fit_db_vs_vsearch > 10)
assert_that(frac_vsearch_vs_fit > 10)
assert_that((open_fit_gg_mcc - open_vsearch_mcc) > 0.20)
assert_that((sec_vsearch_vs_open_fit_db - sec_closed_fit_db_vs_vsearch) < 5)
```

To compare to the reference clustering methods used by QIIME2, we clustered each
dataset with VSEARCH against the Greengenes database of OTUs previously 
clustered at 97% sequence similarity.
Each reference OTU from the Greengenes 97% database contains one reference
sequence, and VSEARCH maps sequences to the reference based on each individual
query sequence's similarity to the single reference sequence.
In contrast, OptiFit accepts reference OTUs which each may contain multiple
sequences, and the sequence similarity between all query and reference sequences
is considered when assigning sequences to OTUs.
<!--**TODO: delete or move this sentence:** _De novo_ clustering with OptiClust produced `r mcc_opticlust_vs_vsearch`%
higher quality OTUs than VSEARCH in terms of MCC, but performed 
`r sec_opticlust_vs_vsearch`% slower than VSEARCH.-->
In closed reference mode, OptiFit produced `r mcc_closed_fit_db_vs_vsearch`%
higher quality OTUs than VSEARCH, but VSEARCH was able to cluster
`r frac_vsearch_vs_fit`% more query sequences than OptiFit to the Greengenes
reference database (Figure \ref{fig:results_sum}).
This is because VSEARCH only considers the distances between each query sequence
to the single reference sequence, while OptiFit considers the distances between
all pairs of reference and query sequences in an OTU. 
When open reference clustering, OptiFit produced higher quality OTUs than
VSEARCH against the Greengenes database, with median MCC scores of 
`r open_fit_gg_mcc` and `r open_vsearch_mcc`, respectively).
In terms of run time, OptiFit outperformed VSEARCH in both closed and open
reference mode by `r sec_closed_fit_db_vs_vsearch`% and 
`r sec_vsearch_vs_open_fit_db`% on average, respectively.
Thus, the more stringent OTU definition employed by OptiFit, which prefers the
query sequence to be similar to all other sequences in the OTU rather than to only one
sequence, resulted in fewer sequences being clustered to reference OTUs than when
using VSEARCH, but caused OptiFit to outperform VSEARCH in terms of both OTU
quality and execution time.

### Reference clustering with split datasets

When performing reference clustering against public databases, the database 
chosen greatly affects the quality of OTUs produced.
OTU quality may be poor when the reference database consists of sequences that
are too unrelated to the samples of interest, such as when samples contain novel
populations.
While _de novo_ clustering overcomes the quality limitations of reference
clustering to databases, OTU assignments are not consistent when new sequences
are added.
Researchers may wish to cluster new sequences to existing OTUs or to compare OTUs
across studies.
To determine how well OptiFit performs for clustering new sequences to existing
OTUs, we employed a split dataset strategy, where each dataset was randomly
split into a reference fraction and a query fraction.
Reference sequences were clustered _de novo_ with OptiClust, then query
sequences were clustered to the _de novo_ OTUs with OptiFit.

```{r, include = FALSE}
close_enough(mcc_opticlust_vs_fit_split_simple, 0.02)
assert_that((frac_fit_split - frac_fit_gg) > 20)
assert_that(!is.unsorted(c(sec_closed_fit_split_vs_db, sec_closed_fit_db_vs_clust, sec_open_fit_split_vs_clust, sec_open_fit_split_vs_db)))
```

First, we tested whether OptiFit performed as well as _de novo_ clustering when
using the split dataset strategy with half of the sequences selected for
the reference by a simple random sample (a 50% split) 
(Figure \ref{fig:results_sum}; self-split).
OTU quality was similar to that from OptiClust regardless of
mode (`r mcc_opticlust_vs_fit_split_simple`% difference in median MCC).
In closed reference mode, OptiFit was able to cluster `r frac_fit_split`% of query
sequences to reference OTUs with the split strategy, a great improvement over
the average `r frac_fit_gg`% of sequences clustered to the Greengenes database.
In terms of run time, closed and open reference OptiFit performed faster than
OptiClust on whole datasets by `r sec_closed_fit_split_vs_clust`% and 
`r sec_open_fit_split_vs_clust`%, respectively.
The split dataset strategy also performed `r sec_closed_fit_split_vs_db`% faster
than the database strategy in closed reference mode and 
`r sec_open_fit_split_vs_db`% faster in open reference mode.
Thus, reference clustering with the split dataset strategy creates as high
quality OTUs as _de novo_ clustering yet at a faster run time, and fits far more
query sequences than the database strategy.

```{r results_split, fig.dim=figs('results_split', 'dim'), fig.cap=figs('results_split', 'cap')}
figs('results_split', 'path') %>% 
  tiff::readTIFF() %>% 
  grid::grid.raster() 
```
```{r, include = FALSE}
close_enough(cv_fit_split_mcc_human_simple, 0, tol = 10^-3)
assert_that(sec_fit_split_human_simple_1 > sec_fit_split_human_simple_9)
assert_that(frac_fit_split_human_simple_1 < frac_fit_split_human_simple_9)
```

While we initially tested this strategy using a 50% split of the data into
reference and query fractions, we next investigated whether there was
an optimal reference fraction size.
To identify the best reference size, reference sets with 10% to 90% of the
sequences were created, with the remaining sequences used for the query 
(Figure \ref{fig:results_split}).
OTU quality was remarkably consistent across reference fraction sizes.
For example, splitting the human dataset 100 times yielded a coefficient of
variation (i.e. the standard deviation divided by the mean) of 
`r cv_fit_split_mcc_human_simple` for the MCC score across all fractions.
Run time generally decreased as the reference fraction increased; for the human
dataset, the median run time was `r sec_fit_split_human_simple_1` seconds with
10% of sequences in the reference and `r sec_fit_split_human_simple_9` seconds
with 90% of sequences in the reference.
In closed reference mode, the fraction of sequences that mapped increased as the
reference size increased; for the human dataset, the median fraction mapped was
`r frac_fit_split_human_simple_1` with 10% of sequences in the reference and 
`r frac_fit_split_human_simple_9` with 90% of sequences in the reference. 
These trends held for the other datasets as well.
Thus, the reference fraction did not affect OTU quality in terms of MCC score,
but did affect the run time and the fraction of sequences that mapped during the
closed reference clustering.

```{r, include = FALSE}
close_enough(c(mcc_fit_split_simple, mcc_fit_split_abun), mcc_fit_split_dist)
assert_that(sec_fit_split_dist < sec_fit_split_abun & sec_fit_split_abun < sec_fit_split_simple)
close_enough(frac_fit_split_simple, frac_fit_split_abun)
assert_that(frac_fit_split_dist < frac_fit_split_simple)
```

After testing the split strategy using a simple random sample to select the
reference sequences, we then investigated other methods of splitting the data.
We tested three methods for selecting the fraction of sequences to be used as
the reference at a size of 50%: a simple random sample, weighting sequences by
relative abundance, and weighting by similarity to other sequences in the
dataset (Figure \ref{fig:results_split}).
OTU quality in terms of MCC was similar across all three sampling methods
(median MCC of `r mcc_fit_split_simple`).
In closed-reference clustering mode, the fraction of sequences that mapped were
similar for simple and abundance-weighted sampling (median fraction mapped of 
`r frac_fit_split_simple` and `r frac_fit_split_abun`, respectively), but worse 
for similarity-weighted sampling (median fraction mapped of `r frac_fit_split_dist`).
While simple and abundance-weighted sampling produced better quality OTUs than
similarity-weighted sampling, OptiFit performed faster on
similarity-weighted samples with a median runtime of `r sec_fit_split_dist`
seconds compared to `r sec_fit_split_abun` and `r sec_fit_split_simple` seconds
for abundance-weighted and simple random sampling, respectively.
Thus, employing more complicated sampling strategies such as abundance-weighted
and similarity-weighted sampling did not confer any advantages over selecting
the reference via a simple random sample, and in fact decreased OTU quality in
the case of similarity-weighted sampling.

## Discussion

We developed a new algorithm for clustering sequences to existing OTUs and have
demonstrated its suitability for reference-based clustering.
OptiFit makes the iterative method employed by OptiClust available for tasks
where reference-based clustering is required.
We have shown that OTU quality is similar between OptiClust and OptiFit in open
reference mode, regardless of strategy employed.
Open reference OptiFit performs slower than OptiClust due to the additional _de
novo_ clustering step, so users may prefer OptiClust for tasks that do not
require reference OTUs.

```{r, include = FALSE}
ref_seqs <- read_tsv(here('subworkflows', '0_prep_db', 'data', 
                          'seq_counts.tsv')) %>% 
  pivot_wider(names_from = ref, values_from = nseqs) %>% as.list()
assert_that(ref_seqs[['rdp']] < ref_seqs[['silva']])
assert_that(ref_seqs[['silva']] < ref_seqs[['gg']])
```

When clustering to public databases, OTU quality dropped in closed reference mode
to different degrees depending on the database and dataset source, and no more
than half of query sequences were able to be clustered into OTUs across any
dataset/database combination. 
This may reflect limitations of reference databases, which are unlikely to
contain sequences from novel microbes.
This drop in quality was most notable with the RDP reference, which contained only 
`r ref_seqs[['rdp']]` sequences compared to `r ref_seqs[['silva']]` sequences in
SILVA and `r ref_seqs[['gg']]` in Greengenes.
Note that Greengenes has not been updated since 2013 at the time of this
writing, while SILVA and the RDP are updated regularly.
We recommend that users who require an independent reference database opt for
large databases with regular updates and good coverage of microbial diversity
for their environment.
Since OptiClust still performs faster than open reference OptiFit and creates
higher quality OTUs than closed reference OptiFit with the database strategy, we
recommend using OptiClust rather than clustering to a database whenever consistent
OTUs are not required.

The OptiClust and OptiFit algorithms produced higher quality
OTUs than VSEARCH in open reference, closed reference, or _de novo_ modes.
However, VSEARCH was able to cluster more sequences to OTUs than OptiFit in closed
reference mode.
While both OptiFit and VSEARCH use a distance or similarity threshold for
determining how to cluster sequences into OTUs, VSEARCH is more permissive than
OptiFit regardless of mode.
The OptiFit and OptiClust algorithms use all of the sequences to define an OTU,
preferring that all pairs of sequences (including reference and query sequences)
in an OTU are within the distance threshold in order to maximize the MCC.
In contrast, VSEARCH only requires each query sequence to be similar to the
single centroid sequence that seeded the OTU.
Because of this, VSEARCH sacrifices OTU quality by allowing more dissimilar
sequences to be clustered into OTUs.

When clustering with the split dataset strategy, OTU quality was remarkably similar
when reference sequences were selected by a simple random sample or weighted by
abundance, but quality was slightly worse when sequences were weighted by
similarity. 
We recommend using a simple random sample since the more
sophisticated reference selection methods do not offer any benefit. 
The similarity in OTU quality between OptiClust and OptiFit with this strategy
demonstrates the suitability of using OptiFit to cluster sequences to existing OTUs,
such as when comparing OTUs across studies.
However, when consistent OTUs are not required, we recommend using OptiClust for
_de novo_ clustering over the split strategy with OptiFit since OptiClust is
simpler to execute but performs similarly in terms of both run time and OTU
quality.

Unlike existing reference-based methods that cluster query sequences to a single
centroid sequence in each reference OTU, OptiFit considers all sequences in each
reference OTU when clustering query sequences, resulting in OTUs of a similar high
quality as those produced by the _de novo_ OptiClust algorithm.
Potential applications include clustering sequences to reference databases,
comparing taxonomic composition of microbiomes across different studies, 
or using OTU-based machine learning models to make predictions on new data.
OptiFit fills the missing option for clustering query sequences to existing OTUs
that does not sacrifice OTU quality for consistency of OTU assignments.

## Materials and Methods

### Data Processing Steps

We downloaded 16S rRNA gene amplicon sequences from four published datasets
isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples.
These datasets contain sequences from the V4 region of the 16S rRNA gene and
represent a selection of the broad types of natural communities that microbial
ecologists study.
We processed the raw sequences using mothur according to the Schloss Lab MiSeq
SOP [@schloss_miseq_nodate] and accompanying study by Kozich _et al._
[@kozich_development_2013].
These steps included trimming and filtering for quality, aligning to the SILVA
reference alignment [@quast_silva_2013], discarding sequences that aligned
outside the V4 region, removing chimeric reads with UCHIME [@edgar_uchime_2011],
and calculating distances between all pairs of sequences within each dataset
prior to clustering.

### Reference database clustering

To generate reference OTUs from independent databases, we downloaded sequences
from the Greengenes database (v13_8_99) [@desantis_greengenes_2006], SILVA
non-redundant database (v132) [@quast_silva_2013], and the Ribosomal Database
Project (v16) [@cole_ribosomal_2014].
These sequences were processed using the same steps outlined above followed by
clustering sequences into _de novo_ OTUs with OptiClust.
Processed reads from each of the four datasets were clustered with OptiFit to
the reference OTUs generated from each of the three databases.
When reference clustering with VSEARCH, processed datasets were clustered directly to
the unprocessed Greengenes 97% OTU reference alignment, since this method is how
VSEARCH is typically used by the QIIME2 software reference-based clustering
[@bolyen_reproducible_2019; @noauthor_clustering_nodate].

### Split dataset clustering

For each dataset, a fraction of the sequences was selected to be clustered _de
novo_ into reference OTUs with OptiClust.
We used three methods for selecting the fraction of sequences to be used
as the reference: a simple random sample, weighting sequences by relative
abundance, and weighting by similarity to other sequences in the dataset.
Dataset splitting was repeated with reference fractions ranging from 10% to 90%
of the dataset and for 100 random seeds.
For each dataset split, the remaining query sequences were clustered into the
reference OTUs with OptiFit.

### Benchmarking

Since OptiClust and OptiFit employ a random number generator to break ties
when OTU assignments are of equal quality, they produce slightly different OTU
assignments when repeated with different random seeds.
To capture any variation in OTU quality or execution time, clustering was
repeated with 100 random seeds for each combination of parameters and
input datasets.
We used the benchmark feature provided by Snakemake to measure the run time of
every clustering job.
We calculated the MCC on each set of OTUs to quantify the quality of clustering,
as described by Westcott _et al._ [@westcott_opticlust_2017].

### Data and Code Availability

We implemented the analysis workflow in Snakemake [@koster_snakemake_2012] and
wrote scripts in R [@r_core_team_r_2020], Python [@van_rossum_python_2009], and
GNU bash [@noauthor_bash_nodate].
Software used includes mothur v1.45.0 [@schloss_introducing_2009], VSEARCH
v2.13.3 [@rognes_vsearch_2016], numpy [@harris_array_2020], the tidyverse
metapackage [@wickham_welcome_2019], R Markdown [@xie_r_2018], ggtext
[@wilke_ggtext_2020], the SRA toolkit [@noauthor_sra-tools_nodate], and the
conda environment manager [@noauthor_anaconda_2016].
The complete workflow, manuscript, and conda environment are available at
https://github.com/SchlossLab/Sovacool_OptiFit_2021.
<!-- TODO: update repo link with journal title -->

## Acknowledgements

We thank members of the Schloss Lab for their feedback on the figures.

KLS received support from the NIH Training Program in Bioinformatics (T32 GM070449).
Salary support for PDS came from NIH grants R01CA215574 and U01AI124255.
The funders had no role in study design, data collection and interpretation, 
or the decision to submit the work for publication.

## Author Contributions

KLS wrote the analysis code, evaluated the algorithm, and wrote the original draft of the manuscript.
SLW designed and implemented the OptiFit algorithm and assisted in debugging the analysis code.
MBM and GAD contributed analysis code.
PDS conceived the study, supervised the project, and assisted in debugging the analysis code.
All authors reviewed and edited the manuscript.

## References
